{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e67787c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-06-09T04:11:34.418147Z",
     "iopub.status.busy": "2023-06-09T04:11:34.417621Z",
     "iopub.status.idle": "2023-06-09T04:11:42.777931Z",
     "shell.execute_reply": "2023-06-09T04:11:42.776918Z"
    },
    "papermill": {
     "duration": 8.384792,
     "end_time": "2023-06-09T04:11:42.780544",
     "exception": false,
     "start_time": "2023-06-09T04:11:34.395752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from tensorflow.compat.v1.logging import INFO, set_verbosity\n",
    "\n",
    "random.seed(a=None, version=2)\n",
    "\n",
    "set_verbosity(INFO)\n",
    "\n",
    "\n",
    "\n",
    "def load_image(img, image_dir, df, preprocess=True, H=320, W=320):\n",
    "    \"\"\"Load and preprocess image.\"\"\"\n",
    "    img_path = image_dir + img\n",
    "    mean, std = get_mean_std_per_batch(img_path, df, H=H, W=W)\n",
    "    x = image.load_img(img_path, target_size=(H, W))\n",
    "    if preprocess:\n",
    "        x -= mean\n",
    "        x /= std\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "    return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f8891b7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-09T04:11:42.803860Z",
     "iopub.status.busy": "2023-06-09T04:11:42.802536Z",
     "iopub.status.idle": "2023-06-09T04:11:56.254097Z",
     "shell.execute_reply": "2023-06-09T04:11:56.253035Z"
    },
    "papermill": {
     "duration": 13.465695,
     "end_time": "2023-06-09T04:11:56.256845",
     "exception": false,
     "start_time": "2023-06-09T04:11:42.791150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -q efficientnet\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# from tensorflow.keras.applications import DenseNet121\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "# import tensorflow.keras.layers as Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0de8510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T04:11:56.279795Z",
     "iopub.status.busy": "2023-06-09T04:11:56.279427Z",
     "iopub.status.idle": "2023-06-09T04:11:56.285236Z",
     "shell.execute_reply": "2023-06-09T04:11:56.284243Z"
    },
    "papermill": {
     "duration": 0.019693,
     "end_time": "2023-06-09T04:11:56.287308",
     "exception": false,
     "start_time": "2023-06-09T04:11:56.267615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8743033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T04:11:56.309732Z",
     "iopub.status.busy": "2023-06-09T04:11:56.309392Z",
     "iopub.status.idle": "2023-06-09T04:11:56.332728Z",
     "shell.execute_reply": "2023-06-09T04:11:56.331743Z"
    },
    "papermill": {
     "duration": 0.037113,
     "end_time": "2023-06-09T04:11:56.334855",
     "exception": false,
     "start_time": "2023-06-09T04:11:56.297742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e2ce4",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.00993,
     "end_time": "2023-06-09T04:11:56.384044",
     "exception": false,
     "start_time": "2023-06-09T04:11:56.374114",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2. Load the Datasets\n",
    "\n",
    "For this assignment, we will be using the [ChestX-ray8 dataset](https://arxiv.org/abs/1705.02315) which contains 108,948 frontal-view X-ray images of 32,717 unique patients. \n",
    "- Each image in the data set contains multiple text-mined labels identifying 14 different pathological conditions. \n",
    "- These in turn can be used by physicians to diagnose 8 different diseases. \n",
    "- We will use this data to develop a single model that will provide binary classification predictions for each of the 14 labeled pathologies. \n",
    "- In other words it will predict 'positive' or 'negative' for each of the pathologies.\n",
    " \n",
    "This dataset has been annotated by consensus among four different radiologists for 5 of our 14 pathologies:\n",
    "- `Consolidation`\n",
    "- `Edema`\n",
    "- `Effusion`\n",
    "- `Cardiomegaly`\n",
    "- `Atelectasis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_main = pd.read_csv('../train_df.csv')\n",
    "# valid_df = pd.read_csv(\"nih/valid-small.csv\")\n",
    "# test_df = pd.read_csv(\"nih/test.csv\")\n",
    "labels = train_df_main.columns[2:-4]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d711aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T04:11:56.845146Z",
     "iopub.status.busy": "2023-06-09T04:11:56.844510Z",
     "iopub.status.idle": "2023-06-09T04:11:56.950844Z",
     "shell.execute_reply": "2023-06-09T04:11:56.949555Z"
    },
    "papermill": {
     "duration": 0.12392,
     "end_time": "2023-06-09T04:11:56.956519",
     "exception": false,
     "start_time": "2023-06-09T04:11:56.832599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, discard = train_test_split(train_df_main, test_size = 0.7, random_state = 1993)\n",
    "\n",
    "train_and_valid_set, test_set = train_test_split(train_df, test_size = 0.2, random_state = 1993)\n",
    "train_set, valid_set = train_test_split(train_and_valid_set, test_size = 0.2, random_state = 1993)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00895c8b",
   "metadata": {
    "papermill": {
     "duration": 0.010149,
     "end_time": "2023-06-09T04:11:57.089725",
     "exception": false,
     "start_time": "2023-06-09T04:11:57.079576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 Preparing Images\n",
    "With our dataset splits ready, we can now proceed with setting up our model to consume them. \n",
    "- For this we will use the off-the-shelf [ImageDataGenerator](https://keras.io/preprocessing/image/) class from the Keras framework, which allows us to build a \"generator\" for images specified in a dataframe. \n",
    "- This class also provides support for basic data augmentation such as random horizontal flipping of images.\n",
    "- We also use the generator to transform the values in each batch so that their mean is $0$ and their standard deviation is 1. \n",
    "    - This will facilitate model training by standardizing the input distribution. \n",
    "- The generator also converts our single channel X-ray images (gray-scale) to a three-channel format by repeating the values in the image across all channels.\n",
    "    - We will want this because the pre-trained model that we'll use requires three-channel inputs.\n",
    "\n",
    "Since it is mainly a matter of reading and understanding Keras documentation, we have implemented the generator for you. There are a few things to note: \n",
    "1. We normalize the mean and standard deviation of the data\n",
    "3. We shuffle the input after each epoch.\n",
    "4. We set the image size to be **320px by 320px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8219ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T04:11:57.112990Z",
     "iopub.status.busy": "2023-06-09T04:11:57.111954Z",
     "iopub.status.idle": "2023-06-09T04:11:57.120401Z",
     "shell.execute_reply": "2023-06-09T04:11:57.119523Z"
    },
    "papermill": {
     "duration": 0.022301,
     "end_time": "2023-06-09T04:11:57.122571",
     "exception": false,
     "start_time": "2023-06-09T04:11:57.100270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "    \n",
    "    print(\"getting train generator...\")\n",
    "    # normalize images\n",
    "    image_generator = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization= True, \n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.15,\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.05,\n",
    "        horizontal_flip=True, \n",
    "        vertical_flip = False, \n",
    "        rescale=1.0/255.0,\n",
    "        fill_mode = 'reflect')\n",
    "    \n",
    "    \n",
    "    # flow from directory with specified batch size\n",
    "    # and target image size\n",
    "    generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=df,\n",
    "            directory=None,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    \n",
    "    return generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23bbce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T04:11:57.165525Z",
     "iopub.status.busy": "2023-06-09T04:11:57.165184Z",
     "iopub.status.idle": "2023-06-09T04:11:57.175292Z",
     "shell.execute_reply": "2023-06-09T04:11:57.174052Z"
    },
    "papermill": {
     "duration": 0.024775,
     "end_time": "2023-06-09T04:11:57.178214",
     "exception": false,
     "start_time": "2023-06-09T04:11:57.153439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "\n",
    "    # get generator to sample dataset\n",
    "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        directory=image_dir, \n",
    "        x_col=\"FilePath\", \n",
    "        y_col=labels, \n",
    "        class_mode=\"raw\", \n",
    "        batch_size=sample_size, \n",
    "        shuffle=True, \n",
    "        target_size=(target_w, target_h))\n",
    "    \n",
    "    # get data sample\n",
    "    batch = raw_train_generator.next()\n",
    "    data_sample = batch[0]\n",
    "\n",
    "    # use sample to fit mean and std for test set generator\n",
    "    image_generator = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization= True)\n",
    "    \n",
    "    # fit generator to sample from training data\n",
    "    image_generator.fit(data_sample)\n",
    "\n",
    "    # get test generator\n",
    "    valid_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=valid_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "\n",
    "    test_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=test_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    return valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a7da5c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T04:11:57.200283Z",
     "iopub.status.busy": "2023-06-09T04:11:57.199937Z",
     "iopub.status.idle": "2023-06-09T04:13:16.809815Z",
     "shell.execute_reply": "2023-06-09T04:13:16.808836Z"
    },
    "papermill": {
     "duration": 79.623493,
     "end_time": "2023-06-09T04:13:16.812144",
     "exception": false,
     "start_time": "2023-06-09T04:11:57.188651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting train generator...\n",
      "Found 21476 validated image filenames.\n",
      "getting train and valid generators...\n",
      "Found 21476 validated image filenames.\n",
      "Found 5370 validated image filenames.\n",
      "Found 6712 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator = get_train_generator(df = train_set,\n",
    "                                      image_dir = None, \n",
    "                                      x_col = \"FilePath\",\n",
    "                                      y_cols = labels, \n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      target_w = IMAGE_SIZE[0], \n",
    "                                      target_h = IMAGE_SIZE[1] \n",
    "                                      )\n",
    "\n",
    "valid_generator, test_generator= get_test_and_valid_generator(valid_df = valid_set, \n",
    "                                                              test_df = test_set, \n",
    "                                                              train_df = train_set,\n",
    "                                                              image_dir = None, \n",
    "                                                              x_col = \"FilePath\", \n",
    "                                                              y_cols = labels,\n",
    "                                                              batch_size = BATCH_SIZE,\n",
    "                                                              target_w = IMAGE_SIZE[0], \n",
    "                                                              target_h = IMAGE_SIZE[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_label(y):\n",
    "    \"\"\"\n",
    "    Returns the appended label list of the given set. \n",
    "    \n",
    "    y(list) the one hot vector list containing the label encoding. \n",
    "    \"\"\"\n",
    "    ret_labels = []\n",
    "    i = 0\n",
    "    for idx in y:\n",
    "        if idx:\n",
    "            ret_labels.append(labels[i])\n",
    "        i += 1\n",
    "    if not ret_labels:\n",
    "        return 'No Label'\n",
    "    else:\n",
    "        return '|'.join(ret_labels)\n",
    "\n",
    "#get one batch of images from the imageset    \n",
    "x, y = train_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c1832f",
   "metadata": {
    "papermill": {
     "duration": 0.01815,
     "end_time": "2023-06-09T04:13:22.005715",
     "exception": false,
     "start_time": "2023-06-09T04:13:21.987565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a name=''>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dd8bdd2",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-09T04:13:22.080478Z",
     "iopub.status.busy": "2023-06-09T04:13:22.080129Z",
     "iopub.status.idle": "2023-06-09T04:13:22.084805Z",
     "shell.execute_reply": "2023-06-09T04:13:22.083926Z"
    },
    "papermill": {
     "duration": 0.026048,
     "end_time": "2023-06-09T04:13:22.086763",
     "exception": false,
     "start_time": "2023-06-09T04:13:22.060715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "#     dnet121 = DenseNet121(input_shape=(*IMAGE_SIZE, 3),\n",
    "#                           weights='imagenet',\n",
    "#                           include_top=False )\n",
    "#     dnet121.trainable = True\n",
    "\n",
    "#     model_dnet121 = tf.keras.Sequential([ dnet121, \n",
    "#                                          Layers.GlobalAveragePooling2D(), \n",
    "#                                          Layers.Dense(len(labels), activation ='sigmoid') ])\n",
    "\n",
    "#     model_dnet121.compile(optimizer='adam',\n",
    "#                            loss = get_weighted_loss(pos_weights, neg_weights), \n",
    "#                            metrics = ['accuracy'] )`\n",
    "\n",
    "#     model_dnet121.summary()\n",
    "\n",
    "# history = model_dnet121.fit_generator(train_generator, \n",
    "#                               validation_data=valid_generator,\n",
    "#                               steps_per_epoch=100, \n",
    "#                               validation_steps=25, \n",
    "#                               epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "addabb33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T04:13:22.125030Z",
     "iopub.status.busy": "2023-06-09T04:13:22.124651Z",
     "iopub.status.idle": "2023-06-09T04:13:22.133422Z",
     "shell.execute_reply": "2023-06-09T04:13:22.132542Z"
    },
    "papermill": {
     "duration": 0.030633,
     "end_time": "2023-06-09T04:13:22.135522",
     "exception": false,
     "start_time": "2023-06-09T04:13:22.104889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Concatenate, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86eb81e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T04:13:22.174099Z",
     "iopub.status.busy": "2023-06-09T04:13:22.173642Z",
     "iopub.status.idle": "2023-06-09T04:13:26.725940Z",
     "shell.execute_reply": "2023-06-09T04:13:26.724971Z"
    },
    "papermill": {
     "duration": 4.57435,
     "end_time": "2023-06-09T04:13:26.728334",
     "exception": false,
     "start_time": "2023-06-09T04:13:22.153984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  \n",
    "    def conv_block(x, growth_rate):\n",
    "        x1 = BatchNormalization()(x)\n",
    "        x1 = ReLU()(x1)\n",
    "        x1 = Conv2D(filters=growth_rate, kernel_size=(3, 3), padding='same')(x1)\n",
    "        x = Concatenate()([x, x1])\n",
    "        return x\n",
    "\n",
    "    def dense_block(x, num_layers, growth_rate):\n",
    "        for _ in range(num_layers):\n",
    "            x = conv_block(x, growth_rate)\n",
    "        return x\n",
    "\n",
    "    def transition_block(x, reduction):\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = Conv2D(int(tf.keras.backend.int_shape(x)[-1] * reduction), kernel_size=(1, 1), padding='same')(x)\n",
    "        x = tf.keras.layers.AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "        return x\n",
    "\n",
    "    def CustomNet121(input_shape=(224, 224, 3), num_classes=1000, growth_rate=32, num_blocks=[6, 12, 24, 16], reduction=0.5):\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "        num_features = 64\n",
    "        for i, num_layers in enumerate(num_blocks):\n",
    "            x = dense_block(x, num_layers, growth_rate)\n",
    "            num_features += num_layers * growth_rate\n",
    "            if i != len(num_blocks) - 1:\n",
    "                x = transition_block(x, reduction)\n",
    "\n",
    "        x = BatchNormalization()(x)\n",
    "        x = ReLU()(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs, x, name='CustomNet-121')\n",
    "        return model\n",
    "    model = CustomNet121(input_shape = (224,224,3),num_classes=len(labels))\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_weights.h5',\n",
    "    monitor='val_accuracy',  # Metric to monitor\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='max'  # Mode of the monitored metric (e.g., max for accuracy, min for loss)\n",
    ")\n",
    "    \n",
    "    \n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam( learning_rate=1e-4, amsgrad=False), \n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['binary_accuracy']\n",
    ")\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a3f0e8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T04:13:28.061581Z",
     "iopub.status.busy": "2023-06-09T04:13:28.061236Z",
     "iopub.status.idle": "2023-06-09T04:13:28.066062Z",
     "shell.execute_reply": "2023-06-09T04:13:28.065027Z"
    },
    "papermill": {
     "duration": 0.027259,
     "end_time": "2023-06-09T04:13:28.068524",
     "exception": false,
     "start_time": "2023-06-09T04:13:28.041265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    monitor='val_accuracy',  # Metric to monitor\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='max'  # Mode of the monitored metric (e.g., max for accuracy, min for loss)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe2d4a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T04:13:28.107059Z",
     "iopub.status.busy": "2023-06-09T04:13:28.106282Z",
     "iopub.status.idle": "2023-06-09T04:13:28.114795Z",
     "shell.execute_reply": "2023-06-09T04:13:28.113818Z"
    },
    "papermill": {
     "duration": 0.03014,
     "end_time": "2023-06-09T04:13:28.116827",
     "exception": false,
     "start_time": "2023-06-09T04:13:28.086687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_lrfn(lr_start=0.002, lr_max=0.010, \n",
    "               lr_min=0, lr_rampup_epochs=8, \n",
    "               lr_sustain_epochs=0, lr_exp_decay=.8):\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup_epochs:\n",
    "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) *\\\n",
    "                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n",
    "                                - lr_sustain_epochs) + lr_min\n",
    "        return lr\n",
    "    return lrfn\n",
    "\n",
    "lrfn = build_lrfn()\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b69e92f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T04:13:28.155413Z",
     "iopub.status.busy": "2023-06-09T04:13:28.155064Z",
     "iopub.status.idle": "2023-06-09T11:16:29.829112Z",
     "shell.execute_reply": "2023-06-09T11:16:29.827106Z"
    },
    "papermill": {
     "duration": 25382.853779,
     "end_time": "2023-06-09T11:16:30.989011",
     "exception": false,
     "start_time": "2023-06-09T04:13:28.135232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4230712904.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.002.\n",
      "Epoch 1/40\n",
      "336/336 [==============================] - 791s 2s/step - loss: 1.6394 - binary_accuracy: 0.9475 - val_loss: 1.7860 - val_binary_accuracy: 0.9491 - lr: 0.0020\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.003.\n",
      "Epoch 2/40\n",
      "336/336 [==============================] - 651s 2s/step - loss: 1.6287 - binary_accuracy: 0.9478 - val_loss: 1.7419 - val_binary_accuracy: 0.9488 - lr: 0.0030\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.004.\n",
      "Epoch 3/40\n",
      "336/336 [==============================] - 578s 2s/step - loss: 1.6080 - binary_accuracy: 0.9478 - val_loss: 2.2601 - val_binary_accuracy: 0.9264 - lr: 0.0040\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 4/40\n",
      "336/336 [==============================] - 614s 2s/step - loss: 1.5902 - binary_accuracy: 0.9478 - val_loss: 1.5900 - val_binary_accuracy: 0.9495 - lr: 0.0050\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.006.\n",
      "Epoch 5/40\n",
      "336/336 [==============================] - 588s 2s/step - loss: 1.5831 - binary_accuracy: 0.9478 - val_loss: 1.5998 - val_binary_accuracy: 0.9495 - lr: 0.0060\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.007.\n",
      "Epoch 6/40\n",
      "336/336 [==============================] - 573s 2s/step - loss: 1.5774 - binary_accuracy: 0.9478 - val_loss: 1.6246 - val_binary_accuracy: 0.9495 - lr: 0.0070\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.008.\n",
      "Epoch 7/40\n",
      "336/336 [==============================] - 661s 2s/step - loss: 1.5728 - binary_accuracy: 0.9478 - val_loss: 1.6060 - val_binary_accuracy: 0.9455 - lr: 0.0080\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.009000000000000001.\n",
      "Epoch 8/40\n",
      "336/336 [==============================] - 605s 2s/step - loss: 1.5696 - binary_accuracy: 0.9478 - val_loss: 1.6192 - val_binary_accuracy: 0.9495 - lr: 0.0090\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 9/40\n",
      "336/336 [==============================] - 586s 2s/step - loss: 1.5646 - binary_accuracy: 0.9478 - val_loss: 1.7351 - val_binary_accuracy: 0.9365 - lr: 0.0100\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.008.\n",
      "Epoch 10/40\n",
      "336/336 [==============================] - 586s 2s/step - loss: 1.5572 - binary_accuracy: 0.9478 - val_loss: 1.6292 - val_binary_accuracy: 0.9488 - lr: 0.0080\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.006400000000000001.\n",
      "Epoch 11/40\n",
      "336/336 [==============================] - 702s 2s/step - loss: 1.5490 - binary_accuracy: 0.9478 - val_loss: 1.5495 - val_binary_accuracy: 0.9495 - lr: 0.0064\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.005120000000000001.\n",
      "Epoch 12/40\n",
      "336/336 [==============================] - 705s 2s/step - loss: 1.5358 - binary_accuracy: 0.9478 - val_loss: 1.5477 - val_binary_accuracy: 0.9477 - lr: 0.0051\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.004096000000000001.\n",
      "Epoch 13/40\n",
      "336/336 [==============================] - 682s 2s/step - loss: 1.5309 - binary_accuracy: 0.9477 - val_loss: 1.5307 - val_binary_accuracy: 0.9495 - lr: 0.0041\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0032768000000000007.\n",
      "Epoch 14/40\n",
      "336/336 [==============================] - 671s 2s/step - loss: 1.5207 - binary_accuracy: 0.9478 - val_loss: 1.5227 - val_binary_accuracy: 0.9493 - lr: 0.0033\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.002621440000000001.\n",
      "Epoch 15/40\n",
      "336/336 [==============================] - 618s 2s/step - loss: 1.5140 - binary_accuracy: 0.9478 - val_loss: 1.5679 - val_binary_accuracy: 0.9475 - lr: 0.0026\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.002097152000000001.\n",
      "Epoch 16/40\n",
      "336/336 [==============================] - 607s 2s/step - loss: 1.5071 - binary_accuracy: 0.9477 - val_loss: 1.5364 - val_binary_accuracy: 0.9495 - lr: 0.0021\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001677721600000001.\n",
      "Epoch 17/40\n",
      "336/336 [==============================] - 622s 2s/step - loss: 1.4997 - binary_accuracy: 0.9478 - val_loss: 1.5203 - val_binary_accuracy: 0.9491 - lr: 0.0017\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0013421772800000006.\n",
      "Epoch 18/40\n",
      "336/336 [==============================] - 619s 2s/step - loss: 1.4916 - binary_accuracy: 0.9478 - val_loss: 1.5253 - val_binary_accuracy: 0.9492 - lr: 0.0013\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0010737418240000006.\n",
      "Epoch 19/40\n",
      "336/336 [==============================] - 691s 2s/step - loss: 1.4851 - binary_accuracy: 0.9477 - val_loss: 1.5046 - val_binary_accuracy: 0.9495 - lr: 0.0011\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0008589934592000006.\n",
      "Epoch 20/40\n",
      "336/336 [==============================] - 657s 2s/step - loss: 1.4809 - binary_accuracy: 0.9477 - val_loss: 1.5279 - val_binary_accuracy: 0.9482 - lr: 8.5899e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0006871947673600004.\n",
      "Epoch 21/40\n",
      "336/336 [==============================] - 600s 2s/step - loss: 1.4733 - binary_accuracy: 0.9478 - val_loss: 1.5031 - val_binary_accuracy: 0.9493 - lr: 6.8719e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0005497558138880004.\n",
      "Epoch 22/40\n",
      "336/336 [==============================] - 597s 2s/step - loss: 1.4673 - binary_accuracy: 0.9478 - val_loss: 1.5067 - val_binary_accuracy: 0.9492 - lr: 5.4976e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.00043980465111040037.\n",
      "Epoch 23/40\n",
      "336/336 [==============================] - 601s 2s/step - loss: 1.4612 - binary_accuracy: 0.9477 - val_loss: 1.5040 - val_binary_accuracy: 0.9491 - lr: 4.3980e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0003518437208883203.\n",
      "Epoch 24/40\n",
      "336/336 [==============================] - 572s 2s/step - loss: 1.4560 - binary_accuracy: 0.9478 - val_loss: 1.4990 - val_binary_accuracy: 0.9493 - lr: 3.5184e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00028147497671065624.\n",
      "Epoch 25/40\n",
      "336/336 [==============================] - 574s 2s/step - loss: 1.4525 - binary_accuracy: 0.9478 - val_loss: 1.4981 - val_binary_accuracy: 0.9491 - lr: 2.8147e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00022517998136852504.\n",
      "Epoch 26/40\n",
      "336/336 [==============================] - 628s 2s/step - loss: 1.4466 - binary_accuracy: 0.9478 - val_loss: 1.5070 - val_binary_accuracy: 0.9486 - lr: 2.2518e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00018014398509482002.\n",
      "Epoch 27/40\n",
      "336/336 [==============================] - 595s 2s/step - loss: 1.4433 - binary_accuracy: 0.9478 - val_loss: 1.5142 - val_binary_accuracy: 0.9482 - lr: 1.8014e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00014411518807585602.\n",
      "Epoch 28/40\n",
      "336/336 [==============================] - 651s 2s/step - loss: 1.4401 - binary_accuracy: 0.9477 - val_loss: 1.5086 - val_binary_accuracy: 0.9484 - lr: 1.4412e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00011529215046068484.\n",
      "Epoch 29/40\n",
      "336/336 [==============================] - 595s 2s/step - loss: 1.4394 - binary_accuracy: 0.9477 - val_loss: 1.5196 - val_binary_accuracy: 0.9480 - lr: 1.1529e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 9.223372036854788e-05.\n",
      "Epoch 30/40\n",
      "336/336 [==============================] - 623s 2s/step - loss: 1.4370 - binary_accuracy: 0.9478 - val_loss: 1.5114 - val_binary_accuracy: 0.9484 - lr: 9.2234e-05\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 7.37869762948383e-05.\n",
      "Epoch 31/40\n",
      "336/336 [==============================] - 579s 2s/step - loss: 1.4338 - binary_accuracy: 0.9477 - val_loss: 1.5093 - val_binary_accuracy: 0.9485 - lr: 7.3787e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 5.902958103587064e-05.\n",
      "Epoch 32/40\n",
      "336/336 [==============================] - 590s 2s/step - loss: 1.4318 - binary_accuracy: 0.9477 - val_loss: 1.5155 - val_binary_accuracy: 0.9482 - lr: 5.9030e-05\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 4.722366482869652e-05.\n",
      "Epoch 33/40\n",
      "336/336 [==============================] - 628s 2s/step - loss: 1.4315 - binary_accuracy: 0.9477 - val_loss: 1.5128 - val_binary_accuracy: 0.9484 - lr: 4.7224e-05\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 3.777893186295722e-05.\n",
      "Epoch 34/40\n",
      "336/336 [==============================] - 597s 2s/step - loss: 1.4316 - binary_accuracy: 0.9477 - val_loss: 1.5146 - val_binary_accuracy: 0.9482 - lr: 3.7779e-05\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 3.0223145490365776e-05.\n",
      "Epoch 35/40\n",
      "336/336 [==============================] - 603s 2s/step - loss: 1.4295 - binary_accuracy: 0.9477 - val_loss: 1.5152 - val_binary_accuracy: 0.9481 - lr: 3.0223e-05\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 2.417851639229262e-05.\n",
      "Epoch 36/40\n",
      "336/336 [==============================] - 624s 2s/step - loss: 1.4292 - binary_accuracy: 0.9478 - val_loss: 1.5144 - val_binary_accuracy: 0.9482 - lr: 2.4179e-05\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 1.9342813113834096e-05.\n",
      "Epoch 37/40\n",
      "336/336 [==============================] - 599s 2s/step - loss: 1.4298 - binary_accuracy: 0.9478 - val_loss: 1.5142 - val_binary_accuracy: 0.9483 - lr: 1.9343e-05\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 1.547425049106728e-05.\n",
      "Epoch 38/40\n",
      "336/336 [==============================] - 617s 2s/step - loss: 1.4281 - binary_accuracy: 0.9478 - val_loss: 1.5147 - val_binary_accuracy: 0.9482 - lr: 1.5474e-05\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 1.2379400392853824e-05.\n",
      "Epoch 39/40\n",
      "336/336 [==============================] - 632s 2s/step - loss: 1.4283 - binary_accuracy: 0.9478 - val_loss: 1.5144 - val_binary_accuracy: 0.9483 - lr: 1.2379e-05\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 9.903520314283058e-06.\n",
      "Epoch 40/40\n",
      "336/336 [==============================] - 612s 2s/step - loss: 1.4269 - binary_accuracy: 0.9478 - val_loss: 1.5160 - val_binary_accuracy: 0.9481 - lr: 9.9035e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "                              validation_data=valid_generator,\n",
    "                              steps_per_epoch=len(train_generator), \n",
    "                              validation_steps=len(valid_generator), \n",
    "                              epochs = 40,\n",
    "                              callbacks=[checkpoint,lr_schedule]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "088c5e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T11:19:32.999410Z",
     "iopub.status.busy": "2023-06-09T11:19:32.999037Z",
     "iopub.status.idle": "2023-06-09T11:19:33.514819Z",
     "shell.execute_reply": "2023-06-09T11:19:33.513882Z"
    },
    "papermill": {
     "duration": 1.69656,
     "end_time": "2023-06-09T11:19:33.517413",
     "exception": false,
     "start_time": "2023-06-09T11:19:31.820853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('chest_xray.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edaa850f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-09T11:19:35.628543Z",
     "iopub.status.busy": "2023-06-09T11:19:35.628024Z",
     "iopub.status.idle": "2023-06-09T11:19:35.659809Z",
     "shell.execute_reply": "2023-06-09T11:19:35.658954Z"
    },
    "papermill": {
     "duration": 1.088863,
     "end_time": "2023-06-09T11:19:35.661895",
     "exception": false,
     "start_time": "2023-06-09T11:19:34.573032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>FilePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91774</th>\n",
       "      <td>00022961_007.png</td>\n",
       "      <td>22961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_010/images/00022961_007.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47366</th>\n",
       "      <td>00012061_001.png</td>\n",
       "      <td>12061</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_006/images/00012061_001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22850</th>\n",
       "      <td>00006049_001.png</td>\n",
       "      <td>6049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_003/images/00006049_001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8739</th>\n",
       "      <td>00002312_004.png</td>\n",
       "      <td>2312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_002/images/00002312_004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43397</th>\n",
       "      <td>00011236_000.png</td>\n",
       "      <td>11236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_005/images/00011236_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23837</th>\n",
       "      <td>00006302_000.png</td>\n",
       "      <td>6302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_003/images/00006302_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>00010695_010.png</td>\n",
       "      <td>10695</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_005/images/00010695_010.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87985</th>\n",
       "      <td>00021824_000.png</td>\n",
       "      <td>21824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_010/images/00021824_000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46777</th>\n",
       "      <td>00011966_007.png</td>\n",
       "      <td>11966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_006/images/00011966_007.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83361</th>\n",
       "      <td>00020509_001.png</td>\n",
       "      <td>20509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/data/images_009/images/00020509_001.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33558 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image Index  Patient ID  Cardiomegaly  Emphysema  Effusion  \\\n",
       "91774  00022961_007.png       22961             0          0         1   \n",
       "47366  00012061_001.png       12061             0          0         0   \n",
       "22850  00006049_001.png        6049             0          0         0   \n",
       "8739   00002312_004.png        2312             0          0         0   \n",
       "43397  00011236_000.png       11236             0          0         0   \n",
       "...                 ...         ...           ...        ...       ...   \n",
       "23837  00006302_000.png        6302             0          0         0   \n",
       "41185  00010695_010.png       10695             0          1         0   \n",
       "87985  00021824_000.png       21824             0          0         0   \n",
       "46777  00011966_007.png       11966             0          0         0   \n",
       "83361  00020509_001.png       20509             0          0         0   \n",
       "\n",
       "       Hernia  Infiltration  Mass  Nodule  Atelectasis  Pneumothorax  \\\n",
       "91774       0             0     0       0            0             0   \n",
       "47366       0             1     0       0            0             0   \n",
       "22850       0             0     0       0            0             0   \n",
       "8739        0             0     0       0            0             0   \n",
       "43397       0             1     0       0            1             0   \n",
       "...       ...           ...   ...     ...          ...           ...   \n",
       "23837       0             0     0       0            0             0   \n",
       "41185       0             0     0       0            0             0   \n",
       "87985       0             0     0       0            0             0   \n",
       "46777       0             0     0       0            0             0   \n",
       "83361       0             0     0       0            0             0   \n",
       "\n",
       "       Pleural_Thickening  Pneumonia  Fibrosis  Edema  Consolidation  \\\n",
       "91774                   0          0         0      0              0   \n",
       "47366                   1          0         0      0              0   \n",
       "22850                   0          0         0      0              0   \n",
       "8739                    0          0         0      0              0   \n",
       "43397                   0          0         0      0              0   \n",
       "...                   ...        ...       ...    ...            ...   \n",
       "23837                   0          0         0      0              0   \n",
       "41185                   0          0         0      0              0   \n",
       "87985                   0          0         0      0              0   \n",
       "46777                   0          1         0      0              0   \n",
       "83361                   0          0         0      0              0   \n",
       "\n",
       "                                               FilePath  \n",
       "91774  ../input/data/images_010/images/00022961_007.png  \n",
       "47366  ../input/data/images_006/images/00012061_001.png  \n",
       "22850  ../input/data/images_003/images/00006049_001.png  \n",
       "8739   ../input/data/images_002/images/00002312_004.png  \n",
       "43397  ../input/data/images_005/images/00011236_000.png  \n",
       "...                                                 ...  \n",
       "23837  ../input/data/images_003/images/00006302_000.png  \n",
       "41185  ../input/data/images_005/images/00010695_010.png  \n",
       "87985  ../input/data/images_010/images/00021824_000.png  \n",
       "46777  ../input/data/images_006/images/00011966_007.png  \n",
       "83361  ../input/data/images_009/images/00020509_001.png  \n",
       "\n",
       "[33558 rows x 17 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d676b976",
   "metadata": {
    "papermill": {
     "duration": 1.17357,
     "end_time": "2023-06-09T11:19:37.915818",
     "exception": false,
     "start_time": "2023-06-09T11:19:36.742248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25698.183646,
   "end_time": "2023-06-09T11:19:42.164637",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-09T04:11:23.980991",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
